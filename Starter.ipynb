{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd9211-efe6-4f46-8e03-608ce8f6b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f059de-dff3-4abc-af6b-d233170c515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281657c-a1b7-4197-ab80-3895588574b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "major = [1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1]\n",
    "m_minor = [1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
    "h_minor = [1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1]\n",
    "h_major = [1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1]\n",
    "wholetone = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
    "octatonic = [1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1]\n",
    "augmented = [1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1]\n",
    "\n",
    "all_scales = [major, m_minor, h_minor, h_major, wholetone, octatonic, augmented]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535c67f-0059-411a-b3d6-bcf8b1658ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transpositions(scale):\n",
    "    transpositions = []\n",
    "\n",
    "    for i in range(12):\n",
    "        current_transposition = scale[-i:] + scale[:-i]\n",
    "        if current_transposition not in transpositions:\n",
    "            transpositions.append(current_transposition)\n",
    "\n",
    "    return np.array(transpositions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c433bff2-886a-445d-bd84-d02e568b8b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_name_base(idx):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a1d89-8171-4e6d-bd1c-cf26122ba856",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_realized_scales = np.concatenate([get_transpositions(s) for s in all_scales])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd831f-a701-47ef-a765-26f792a3d0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_common_tones = all_realized_scales @ all_realized_scales.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5a82a2-2a7e-44fd-bafe-57e7f825378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(n_common_tones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9631b37a-926a-4832-8226-f4c8e0b37262",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_common_tones[0, :12], n_common_tones[0, 12:24], n_common_tones[0, 24:36], n_common_tones[0, 36:48], n_common_tones[0, 48:50], n_common_tones[0, 50:53], n_common_tones[0, 53:57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c68385-5732-431d-8699-88e2b452fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_common_tones[12, 12:24], n_common_tones[12, 24:36], n_common_tones[12, 36:48], n_common_tones[12, 48:50], n_common_tones[12, 50:53], n_common_tones[12, 53:57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e4d0b0-8580-4c27-b03d-7e93326a633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_common_tones[24, 24:36], n_common_tones[24, 36:48], n_common_tones[24, 48:50], n_common_tones[24, 50:53], n_common_tones[24, 53:57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7f59c3-386c-4e17-8282-6b63258bd294",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_common_tones[36, 36:48], n_common_tones[36, 48:50], n_common_tones[36, 50:53], n_common_tones[36, 53:57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eac794-c691-49b3-bc0c-49807ea56963",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_common_tones[48, 48:50], n_common_tones[48, 50:53], n_common_tones[48, 53:57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e3376-afaf-4bf7-a4c7-8112e4c25b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_common_tones[50, 50:53], n_common_tones[50, 53:57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ba91f-12f9-4db7-a23d-1d41d494c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = np.argwhere(n_common_tones == 2)\n",
    "pairs = pairs[pairs[:, 0] < pairs[:, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82e1299-df5a-4283-aa52-dd42c6c77244",
   "metadata": {},
   "source": [
    "## Back to graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc668b43-4cba-4497-b331-d67f20155727",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = 'DFKk'\n",
    "colors = ['tab:red', 'tab:green', 'tab:blue', 'tab:orange']\n",
    "color_table = {a: c for a, c in zip(scales, colors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cfb2e4-e906-40d0-9d3e-f57673c234c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put color and label into node attributes\n",
    "\n",
    "nodes = [(a, n) for a, n in product(scales, range(12))]\n",
    "node_colors = [color_table[a[0]] for a in nodes]\n",
    "node_labels = {str(a): f'${a[0]}_{{{a[1]}}}$' for a in nodes}\n",
    "\n",
    "DG = nx.DiGraph()\n",
    "DG.add_nodes_from(str(n) for n in nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded34910-6ba1-4942-8046-416182ada774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: there are duplicate edges\n",
    "edges = []\n",
    "for idx in range(12):\n",
    "    edges.append((('D', idx), ('D', (idx+7) % 12)))\n",
    "    edges.append((('D', idx), ('F', (idx+7) % 12)))\n",
    "    edges.append((('D', idx), ('k', (idx) % 12)))\n",
    "    edges.append((('F', idx), ('D', (idx+7) % 12)))\n",
    "    edges.append((('F', idx), ('K', (idx+2) % 12)))\n",
    "    edges.append((('k', idx), ('K', (idx+9) % 12)))\n",
    "    edges.append((('k', idx), ('F', (idx+2) % 12)))\n",
    "    edges.append((('K', idx), ('D', (idx) % 12)))\n",
    "\n",
    "DG.add_edges_from((str(e[0]), str(e[1])) for e in edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e51edf7-25ad-4d01-9314-b89cfbd97417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add irregular nodes\n",
    "# wholetone\n",
    "color_table['W'] = 'tab:purple'\n",
    "W = [('W', 0), ('W', 1)]\n",
    "node_colors.extend([color_table[a[0]] for a in W])\n",
    "node_labels.update({str(a): f'${a[0]}_{{{a[1]}}}$' for a in W})\n",
    "DG.add_nodes_from(str(n) for n in W)\n",
    "\n",
    "edges = []\n",
    "for idx in range(12):\n",
    "    edges.append((('F', idx), ('W', (idx) % 2)))\n",
    "\n",
    "DG.add_edges_from((str(e[0]), str(e[1])) for e in edges)\n",
    "\n",
    "#augmented\n",
    "color_table['A'] = 'tab:cyan'\n",
    "A = [('A', 0), ('A', 1), ('A', 2), ('A', 3)]\n",
    "node_colors.extend([color_table[a[0]] for a in A])\n",
    "node_labels.update({str(a): f'${a[0]}_{{{a[1]}}}$' for a in A})\n",
    "DG.add_nodes_from(str(n) for n in A)\n",
    "\n",
    "edges = []\n",
    "for idx in range(12):\n",
    "    edges.append((('k', idx), ('A', (idx + 3) % 4)))\n",
    "    edges.append((('K', idx), ('A', (idx + 2) % 4)))\n",
    "\n",
    "DG.add_edges_from((str(e[0]), str(e[1])) for e in edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2c54b-7e2f-4edf-80e8-b950b8d1280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(DG, pos=nx.spectral_layout(DG), labels=node_labels, node_color=node_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481df8ea-20df-47e4-bf5b-8aad859fa72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(\n",
    "    notebook=True,\n",
    "    directed = True,\n",
    "    select_menu = True,\n",
    "    filter_menu = True,\n",
    "    cdn_resources='in_line',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9a3664-f997-43d2-ae05-ab8c23e2110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.show_buttons()\n",
    "net.from_nx(DG)\n",
    "net.show('graph.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec018bd4-fd72-495f-b785-0d34c33bbed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "major = np.array([1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n",
    "m_minor = np.array([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1])\n",
    "h_minor = np.array([1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1])\n",
    "h_major = np.array([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1])\n",
    "wholetone = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
    "octatonic = np.array([1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1])\n",
    "augmented = np.array([1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1])\n",
    "\n",
    "families = [major, m_minor, h_minor, h_major, wholetone, octatonic, augmented]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44133a79-d0cb-4653-bfb1-dd11135a0f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_same_family(a, b):\n",
    "    if sum(a) != sum(b):\n",
    "        return False\n",
    "\n",
    "    return max(np.correlate(a, np.concatenate((b, b)), mode='valid')) == sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3fe78-5672-44f4-aeaa-b55cee752306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen(a, idx):\n",
    "    result = np.copy(a)\n",
    "    result[idx] = 0\n",
    "    result[(idx + 1) % 12] = 1\n",
    "\n",
    "    return result\n",
    "\n",
    "def flatten(a, idx):\n",
    "    result = np.copy(a)\n",
    "    result[idx] = 0\n",
    "    result[(idx - 1) % 12] = 1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e623f0-cb76-45dc-b386-bacaa535c2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_modifications(scale):\n",
    "    print('sharps')\n",
    "    for idx in np.argwhere(scale == 1):\n",
    "        if scale[(idx + 1) % 12] == 0:\n",
    "            new_scale = sharpen(scale, idx)\n",
    "            if any(are_same_family(new_scale, other) for other in families):\n",
    "                print(idx)\n",
    "    print('flats')\n",
    "    for idx in np.argwhere(scale == 1):\n",
    "        if scale[(idx - 1) % 12] == 0:\n",
    "            new_scale = flatten(scale, idx)\n",
    "            if any(are_same_family(new_scale, other) for other in families):\n",
    "                print(idx)\n",
    "\n",
    "    print('sharpen add note')\n",
    "    for idx in np.argwhere(scale == 1):\n",
    "        if scale[(idx + 1) % 12] == 0:\n",
    "            new_scale = sharpen(scale, idx)\n",
    "            for jdx in np.argwhere(new_scale == 0):\n",
    "                new_new_scale = np.copy(new_scale)\n",
    "                new_new_scale[jdx] = 1\n",
    "                if any(are_same_family(new_new_scale, other) for other in families):\n",
    "                    print(idx, jdx)\n",
    "\n",
    "    print('flatten add note')\n",
    "    for idx in np.argwhere(scale == 1):\n",
    "        if scale[(idx - 1) % 12] == 0:\n",
    "            new_scale = flatten(scale, idx)\n",
    "            for jdx in np.argwhere(new_scale == 0):\n",
    "                new_new_scale = np.copy(new_scale)\n",
    "                new_new_scale[jdx] = 1\n",
    "                if any(are_same_family(new_new_scale, other) for other in families):\n",
    "                    print(idx, jdx)\n",
    "\n",
    "    print('sharpen remove note')\n",
    "    for idx in np.argwhere(scale == 1):\n",
    "        if scale[(idx + 1) % 12] == 0:\n",
    "            new_scale = sharpen(scale, idx)\n",
    "            for jdx in np.argwhere(new_scale == 1):\n",
    "                new_new_scale = np.copy(new_scale)\n",
    "                new_new_scale[jdx] = 0\n",
    "                if any(are_same_family(new_new_scale, other) for other in families):\n",
    "                    print(idx, jdx)\n",
    "\n",
    "    print('flatten remove note')\n",
    "    for idx in np.argwhere(scale == 1):\n",
    "        if scale[(idx - 1) % 12] == 0:\n",
    "            new_scale = flatten(scale, idx)\n",
    "            for jdx in np.argwhere(new_scale == 1):\n",
    "                new_new_scale = np.copy(new_scale)\n",
    "                new_new_scale[jdx] = 0\n",
    "                if any(are_same_family(new_new_scale, other) for other in families):\n",
    "                    print(idx, jdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc39c6-aaae-4c41-86f2-7b292c80fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scale in families:\n",
    "    print(scale)\n",
    "    print('------')\n",
    "    available_modifications(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512a9c7-d3f7-4492-a05e-a682695a9cfb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## TODOs\n",
    "\n",
    "We are working with `triadic scales` ie. scales where the intervals between every other note is either 3 (minor third) or 4 (major third). In 12-EDO only major, melodic minor, harmonic major, harmonic minor, wholetone, octatonic, and augmented scales stisfy this condition. First 4 are ordinary 7-tone scales, while the last three are modes of limited transposition (2, 3, 4 transpositions respectively).\n",
    "\n",
    "We have defined a sort of normalized form for all \"proper scales\" (scales that have 12 transpositions): The mode that starts on the axis of symmetry is the cannonical form.\n",
    "\n",
    "For almost all scales, inverse of the scale is equivalent to som rotation of itself. Only harmonic minor's inverse is the harmonic major and vice verse.\n",
    "\n",
    "The fundamental operation is `sharpen`. All `flatten` operations are inverses of some sharpen operation. These operations let us map the relationships between all proper scales. To include modes of limited transposition we introduce a set of new operations: `sharpen/flatten and add/remove note`.\n",
    "\n",
    "We need to find for each scale, which transformations are available and to which scale family's which transposition does a transformation take us.\n",
    "\n",
    "We will consider only `sharpen`, `sharpen and add note`, and `sharpen and remove note` operations since all `flatten` equivalents are inverses of some of those.\n",
    "\n",
    "```\n",
    "sharpen(i)\n",
    "flatten(i)\n",
    "sharpen/flatten_and_add/remove note(i, j)\n",
    "```\n",
    "\n",
    "### Scale class\n",
    "Every scale has a family, a cannonical form and a realization. Given an `other` scale, `scale` class must have `is_from_same_family`, `which_transposition` operations. Also a `num_transpositions` to see how many transpositions it has. Transformations must be defined as functions, and an utility function that takes a transformation and a scale and returns a list of results must be defined.\n",
    "\n",
    "Scales also must have a `get_name` method (`__repr__` or `__str__` or both?), which returns $F_n$, scale family and transposition, and `get_scale`, which returns the scale as a numpy array.\n",
    "\n",
    "Maybe `available_transformations` can also be a method. So we can keep track of which transformations are available to a scale and where they take us. For this, we might need to define transformations as a class.\n",
    "\n",
    "We can also incorporate modes. For example, `num_modes` to get number of available modes of a scale (generally 7 but 1, 2, 2 for wholetone, octatonic, and augmented respectively). We can ask for the base pitch of $n^{th}$ mode of a scale. We can also ask for equivalent base pitches for a mode of limited transposition, eg. only transpositions of W are $W_0$ and $W_1$ but they are alsop the same as `(0, 2, 4, 6, 8, 10)` and `(1, 3, 5, 7, 9, 11)` respectively. However, this might be confusing.\n",
    "\n",
    "Finally, if two different transformation of a scale takes us to the same transposition of the same family find a way to merge them into one single transformation.\n",
    "\n",
    "### Note on irregular scales\n",
    "Irregular scales are like wormholes between distant tones. We can exclude them for some purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c45fc-3240-42c3-a50e-b229a8933174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale families are just the cannonical form of the scale and its name\n",
    "\n",
    "class ScaleFamily:\n",
    "    def __init__(self, name: str, letter: str, cannonical_form: np.array):\n",
    "        self.name = name\n",
    "        self.letter = letter\n",
    "        self.cannonical_form = cannonical_form\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.name}: {self.cannonical_form}'\n",
    "\n",
    "# Cannonical form of the major family of modes is the second mode, Dorian.\n",
    "# Therefore we will call this the dorian family.\n",
    "dorian_family = ScaleFamily('Dorian', 'D', np.array([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0]))\n",
    "# For modes of the melodic minor, the cannonical form is the 5th mode\n",
    "fifth_mode_family = ScaleFamily('Fifth Mode', 'F', np.array([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0]))\n",
    "# For harmonic minor, it's the 4th mode\n",
    "harmonic_minor_4 = ScaleFamily('Fourth of Harmonic Minor', 'k', np.array([1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1]))\n",
    "# For harmonic major, it's the 2nd mode\n",
    "harmonic_major_2 = ScaleFamily('Second of Harmonic Major', 'K', np.array([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1]))\n",
    "# Irregular scales don't have an axis of symmetry, so we will select the modes that start with the largest interval\n",
    "wholetone = ScaleFamily('Wholetone', 'W', np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]))\n",
    "octatonic = ScaleFamily('Octatonic', 'O', np.array([1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1]))\n",
    "augmented = ScaleFamily('Augmented', 'A', np.array([1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1]))\n",
    "\n",
    "# all scale families in a list for convenience\n",
    "scale_families = [dorian_family, fifth_mode_family, harmonic_minor_4, harmonic_major_2, wholetone, octatonic, augmented]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe8e58-2f51-4dc9-ad63-5bdb303345e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0])\n",
    "b = np.array([1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n",
    "\n",
    "assert (num_voices := sum(a)) == sum(b)\n",
    "correlation = np.correlate(a, np.concatenate((b, b)), mode='valid')\n",
    "\n",
    "idx = np.argmax(correlation)\n",
    "value = correlation[idx]\n",
    "assert value == num_voices\n",
    "\n",
    "f'scale b is tranpose {idx} of scale a. iff they have the same number of voices and {value=} == {num_voices=}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c7414-1a43-45ce-b6d6-2db274734008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
